# 3.19 去重功能代码我是这样设计的

**视频讲解：**
[![#20 去重是如何实现的.mp4 (476.42MB)](./img/SKhTvRfRY2L0KT1v/1715182390798-8898196c-c9e7-4e80-ab68-9f7df75762fe-397950.png)](https://www.yuque.com/u37247843/dg9569/xns60vdh5ctpy0qt?_lake_card=%7B%22status%22%3A%22done%22%2C%22name%22%3A%22%2320%20%E5%8E%BB%E9%87%8D%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%9A%84.mp4%22%2C%22size%22%3A499563975%2C%22taskId%22%3A%22u14d2c09e-2a27-4d43-ac0e-51ffa454df3%22%2C%22taskType%22%3A%22upload%22%2C%22url%22%3Anull%2C%22cover%22%3Anull%2C%22videoId%22%3A%22inputs%2Fprod%2Fyuque%2F2023%2F1285871%2Fmp4%2F1687268636517-bfedaf65-2805-447f-a197-dbd927a937c3.mp4%22%2C%22download%22%3Afalse%2C%22__spacing%22%3A%22both%22%2C%22id%22%3A%22OZANx%22%2C%22margin%22%3A%7B%22top%22%3Atrue%2C%22bottom%22%3Atrue%7D%2C%22card%22%3A%22video%22%7D#OZANx)austin支持两种去重的类型：**N分钟相同内容达到N次**去重和**一天内N次相同渠道频次**去重。

在最开始，我的第一版实现是这样的：
```
public void duplication(TaskInfo taskInfo) {
    // 配置示例:{"contentDeduplication":{"num":1,"time":300},"frequencyDeduplication":{"num":5}}
    JSONObject property = JSON.parseObject(config.getProperty(DEDUPLICATION_RULE_KEY, AustinConstant.APOLLO_DEFAULT_VALUE_JSON_OBJECT));
JSONObject contentDeduplication = property.getJSONObject(CONTENT_DEDUPLICATION);
JSONObject frequencyDeduplication = property.getJSONObject(FREQUENCY_DEDUPLICATION);

// 文案去重
DeduplicationParam contentParams = DeduplicationParam.builder()
    .deduplicationTime(contentDeduplication.getLong(TIME))
    .countNum(contentDeduplication.getInteger(NUM)).taskInfo(taskInfo)
    .anchorState(AnchorState.CONTENT_DEDUPLICATION)
    .build();
contentDeduplicationService.deduplication(contentParams);


// 运营总规则去重(一天内用户收到最多同一个渠道的消息次数)
Long seconds = (DateUtil.endOfDay(new Date()).getTime() - DateUtil.current()) / 1000;
DeduplicationParam businessParams = DeduplicationParam.builder()
    .deduplicationTime(seconds)
    .countNum(frequencyDeduplication.getInteger(NUM)).taskInfo(taskInfo)
    .anchorState(AnchorState.RULE_DEDUPLICATION)
    .build();
frequencyDeduplicationService.deduplication(businessParams);
}
```
那时候很简单，**基本主体逻辑都写在这个入口上了**，应该都能看得懂。后来，群里滴滴哥表示这种代码不行，不能一眼看出来它干了什么。于是重构了一版，入口是这样的：
```
public void duplication(TaskInfo taskInfo) {

    // 配置样例：{"contentDeduplication":{"num":1,"time":300},"frequencyDeduplication":{"num":5}}
    String deduplication = config.getProperty(DeduplicationConstants.DEDUPLICATION_RULE_KEY, AustinConstant.APOLLO_DEFAULT_VALUE_JSON_OBJECT);

//去重
DEDUPLICATION_LIST.forEach(
    key -> {
        DeduplicationParam deduplicationParam = builderFactory.select(key).build(deduplication, key);
        if (deduplicationParam != null) {
            deduplicationParam.setTaskInfo(taskInfo);
            DeduplicationService deduplicationService = findService(key + SERVICE);
            deduplicationService.deduplication(deduplicationParam);
        }
    }
);
}
```
他的思路就是把**构建去重参数**和**选择具体的去重服务**给封装起来了，在最外层的代码看起来就很简洁了。
后来，我基于上面的思路微改了下，代码最终演变成这样：
```
public void duplication(TaskInfo taskInfo) {
    // 配置样例：{"deduplication_10":{"num":1,"time":300},"deduplication_20":{"num":5}}
    String deduplicationConfig = config.getProperty(DEDUPLICATION_RULE_KEY, CommonConstant.EMPTY_JSON_OBJECT);

// 去重
List<Integer> deduplicationList = DeduplicationType.getDeduplicationList();
for (Integer deduplicationType : deduplicationList) {
    DeduplicationParam deduplicationParam = deduplicationHolder.selectBuilder(deduplicationType).build(deduplicationConfig, taskInfo);
    if (Objects.nonNull(deduplicationParam)) {
        deduplicationHolder.selectService(deduplicationType).deduplication(deduplicationParam);
    }
}
}
```
到这，应该大多数人还能跟上吧？在讲具体的代码之前，我们先来简单看看去重功能的代码结构（这会对后面看代码有帮助）
![1678266541619-38c2f272-c649-4e4d-bf33-ad1ed0b6fe0d.png](./img/SKhTvRfRY2L0KT1v/1678266541619-38c2f272-c649-4e4d-bf33-ad1ed0b6fe0d-117764.png)

**注：**入口现已移到**com.java3y.austin.handler.action.DeduplicationAction#process**

去重的逻辑可以**统一抽象**为：在**X时间段**内达到了**Y阈值**，还记得我曾经说过：**「去重」的本质：「业务Key」+「存储」**。那么去重实现的步骤可以简单分为（**我这边存储就用的Redis**）：

- 通过Key从Redis获取记录
- 判断该Key在Redis的记录是否符合条件
- 符合条件的则去重，不符合条件的则重新塞进Redis更新记录

为了方便调整去重的参数，我把**X时间段**和**Y阈值**都**放到了配置里**{"deduplication_10":{"num":1,"time":300},"deduplication_20":{"num":5}}。目前有两种去重的具体实现：

1、5分钟内相同用户如果收到相同的内容，则应该被过滤掉
2、一天内相同的用户如果已经收到某渠道内容5次，则应该被过滤掉

从配置中心拿到配置信息了以后，Builder就是根据这两种类型去构建出DeduplicationParam。
Builder和DeduplicationService都用了类似的写法（**在子类初始化的时候指定类型，在父类统一接收，放到Map里管理**）
![1678266541611-4137ba11-c213-4432-ac3e-5505ab125999.png](./img/SKhTvRfRY2L0KT1v/1678266541611-4137ba11-c213-4432-ac3e-5505ab125999-766742.png)
![1678266541424-a61ec2c3-881f-4c62-9e48-3108f8960fd8.png](./img/SKhTvRfRY2L0KT1v/1678266541424-a61ec2c3-881f-4c62-9e48-3108f8960fd8-961757.png)
而统一管理这些服务，有个中心的地方，我把这取名为DeduplicationHolder
```
/**
* @author huskey
* @date 2022/1/18
*/
@Service
public class DeduplicationHolder {

    private final Map<Integer, Builder> builderHolder = new HashMap<>(4);
    private final Map<Integer, DeduplicationService> serviceHolder = new HashMap<>(4);

    public Builder selectBuilder(Integer key) {
        return builderHolder.get(key);
    }

    public DeduplicationService selectService(Integer key) {
        return serviceHolder.get(key);
    }

    public void putBuilder(Integer key, Builder builder) {
        builderHolder.put(key, builder);
    }

    public void putService(Integer key, DeduplicationService service) {
        serviceHolder.put(key, service);
    }
}
```
前面提到的**业务Key**，是在AbstractDeduplicationService的子类下构建的：
![1678266541544-c8baf766-d641-43e4-b297-dc4e0740a2e3.png](./img/SKhTvRfRY2L0KT1v/1678266541544-c8baf766-d641-43e4-b297-dc4e0740a2e3-020063.png)
而具体的去重逻辑实现则都在LimitService下，**{一天内相同的用户如果已经收到某渠道内容5次}**是在SimpleLimitService中处理使用mget和pipelineSetEX就完成了实现。而**{5分钟内相同用户如果收到相同的内容}**是在SlideWindowLimitService中处理，使用了lua脚本完成了实现。
![1678266541515-5c9db970-5dc1-4a7f-a145-fc7010d16a77.png](./img/SKhTvRfRY2L0KT1v/1678266541515-5c9db970-5dc1-4a7f-a145-fc7010d16a77-366516.png)



LimitService的代码都来源于@[caolongxiu](https://gitee.com/caolongxiu)的pull request，**建议大家可以对比commit再学习一番**：[https://gitee.com/zhongfucheng/austin/pulls/19](https://gitee.com/zhongfucheng/austin/pulls/19)

> _1、频次去重采用普通的计数去重方法，限制的是每天发送的条数。_
> _2、内容去重采用的是新开发的基于redis中zset的滑动窗口去重，**可以做到严格控制单位时间内的频次**。3、redis使用lua脚本来保证原子性和减少网络io的损耗_
> _4、redis的key增加前缀做到数据隔离（后期可能有动态更换去重方法的需求）_
> _5、把具体限流去重方法从DeduplicationService抽取出来，DeduplicationService只需设置构造器注入时注入的AbstractLimitService（具体限流去重服务）类型即可动态更换去重的方法6、使用雪花算法生成zset的唯一value,score使用的是当前的时间戳_


针对滑动窗口去重，会引申出新的常见问题：

**Q：为什么要用滑动窗口？用redis的过期时间和这个相比两个的区别在哪里**
**A：**
![image.png](./img/SKhTvRfRY2L0KT1v/1711013968786-12320774-6dbb-47bd-91f1-19b30c200ed7-739302.png)

**Q：limit.lua的逻辑？为什么要移除时间窗口的之前的数据？为什么ARGV[4]参数要唯一？为什么要expire？**
![1662301599423-05b3465c-6641-4afb-94ea-8e20796c96f9.png](./img/SKhTvRfRY2L0KT1v/1662301599423-05b3465c-6641-4afb-94ea-8e20796c96f9-113932.png)
**A：**使用**滑动窗口**可以保证N分钟达到N次进行去重。滑动窗口可以回顾下TCP的，也可以回顾下刷LeetCode时的一些算法题，那这为什么要移除，就不陌生了。
为什么ARGV[4]要唯一，具体可以看看zadd这条命令，我们只需要保证每次add进窗口内的成员是唯一的，那么就**不会触发有更新的操作**（我认为这样设计会更加简单些），而唯一Key用雪花算法比较方便。
为什么expire？，如果这个key只被调用一次。那就很有可能在redis内存常驻了


> 原文: <https://www.yuque.com/u37247843/dg9569/xns60vdh5ctpy0qt>